 - when an api request is made but the connection breaks during read the request fails with no httpresponse error code because communications were dirupted.

 - need to give all exceptions an "out" to whatever process is running that breaks the program in a benign way so that the location of error is known and can be logged accurately in the container program.

 - program is not aware of what it needs from the handbook in order to run properly (assuming the config is inproperly configured or api does not have requested data type such as USD and BTC as asset_id_quote and asset_id_base for handbook["exchanges"] which is needed for gathering the correct type of historical data of coins)

 - if a json file exsists but does not have the right keys or format the program will break

 - check to see if database.UpdateIndex() will run into errors when run such as it trying to write to files that arn't there if called in certain spots of code. etc

 - error catching for all possabilities within database.BackfillHistoricalData() and related

 - should put handbook last update value in handbook.json not config.json

 - for api_index.json, coinAPI doesn't properly initialize it to track when the next api refresh will be or if the file does not exist it will crash.

 - when opening files, have an if statement with os.path.exists instead of a try - catch statement.

 - if the coinAPI api_index is not loaded or initialized as intended (which is possible), the api limit will default to 0 and not let any requests through.

 - for timestamps, if data from coin_api is given to us with a value other than 0 in the ten millions place (possible) it will raise an error in database.BackfillHistoricalData(). As I write this entry, we currently have that digit hard-coded as 0 right before the Z "0Z". For example, if coin_api sends 2016-02-07T09:17:00.0000004Z my program will convert it to unix and compare for validity but will output 2016-02-07T09:17:00.0000000Z since that last digit is hard-coded to 0. The program will think the data has been altered (and it was) in the unix time conversion, killing the process.

 - implement database.ReloadHistoricalIndex() and database.ReloadTrainingIndex(). If the data in any index.json files are corrupted or altered to not match the actual data, there needs to be a way of reloading that index. Currently there is none so if that happens we are SOL.

 - ideally, historical_index and training_index are just a list of all index_data regardless of exchange_id. This way you can loop through them will a single for loop (rather than nested loop). Not to mention the fact that loading a specific index is self.historical_index[filename] instead of self.historical_index[exchange_id][filename]. Plus you can still isolate them in the directory when storing the files since the exchange_id data is within each index_item anyway.

- optimize historical backfill time-step verification (takes way to long)

- SERIOUS FLAW in database.__InitHistoricalDir() and database.InitTrainingDir() when they initialize the index.json file. If an exception is thrown while reading the file the index in memory will be erased. Since there is no ReloadIndex() functionality the data is lost and the program will not work.

- in database.__InitHistoricalDir() and database.InitTrainingDir(), if there is no data for them to work off of in an entire exchange, they will make a blank file database/training_data/(exchange_id) or database/historical_data/(exchange_id)

- if an empty dictionary is passed to coin_api.CheckForKey(), particularly in coin_api.FilterJson() then the function may crash

- I ran a backfill on XRP for the most recent data at 9:13 but it gave me data for 9:15, MAKE SURE the data is not partial for that time period (I think they just send what they have so far instead of waiting for the full period to elapse)

- a system to monitor each coins data_end value so that only training_data files are only created when all included coins have the same data_end value and it is equivalent to the historical_data end value.





///EFFICIENCY GAINS///

- training_index and historical_index start with an empty dictionary at startup within database.__InitHistoricalDir() and database.__InitTrainingDir(). It then loads all tracked exchanges regardless of whether or not we hae that data already. It finally loads all **_index.json files and overwrites any items that were created at initialization.

- there are multiple copies of the SetDateToUnix and SetUnixToDate functions. They need to be consolidated to one spot somhow

- a system to monitor each coins data_end value so that only training_data files are only created when all included coins have the same data_end value and it is equivalent to the historical_data end value.