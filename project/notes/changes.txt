
NOTE: change of plans. 
I originally had training_data convert values to the slope form but wanted to have gaps filled and columns dropped
outside the training_data methods and datasets. Fuck that.
Instead, I will have the training_data made on demand by the neural net using the database method. The data will be defined
by several parameters and training_data will only regenerate the training_data if the requested data parameters do not match
the parameters for existing data OR the training_data is behind the historical_data (unless told otherwise). This is only 
necessary in the testing and neural hyper-parameter optimization phase (once an ideal parameter set is found, the program 
should only use that one style of training_data and update from historical accordingly).

NEEDS SIMULTANEOUS CRYPTO CAPABILITIES,
ALSO NEEDS NEW NAMING CONVENTIONS FOR TRAINING_DATA
This is largely because multiple coins will be associated with certain datasets within training_data

This will also require a new sequence algorithm for neural_net. Since datapoints are missing, a new 
sequence generator algorithm will need to be made. The minimum allowable 
continuous chain of datapoints will be equal to SEQ_LEN. This may mean that a wildly different number of 
training_data will actually be usable by the model depending on configuration.

I want to be able to "query" the training_data with a dictionary of the desired parameters.


The parameters that I would like to have implemented for this iteration are as follows:
- max_filler_gap (maximum sized gap allowed to be filled, this is done with averages)
- included columns
- included currencies in an order consistent with how they are trained (id them with filename)


AGENDA:

- create a model accuracy system to rate the performance of a model
after being trained

- save the model hyper-parameters, the model_ready data parameters and
the trained model itself within a filesystem. ideally utilizing database